{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01030953-31aa-474e-86da-5140d0c19504",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Ignoring XDG_SESSION_TYPE=wayland on Gnome. Use QT_QPA_PLATFORM=wayland to run on Wayland anyway.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# --- Select your ArUco dictionary (DICT_4X4_50 is common) ---\n",
    "aruco_dict = cv2.aruco.getPredefinedDictionary(cv2.aruco.DICT_4X4_50) # 50 unique patterns possible \n",
    "aruco_params = cv2.aruco.DetectorParameters() # object containing thresholds, corner refinemet options, sensitvity tuning etc\n",
    "\n",
    "# --- Open the webcam ---\n",
    "cap = cv2.VideoCapture(2)   # /dev/video2\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Could not open webcam\")\n",
    "    exit()\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read() # fram is a numpy array of shape (height, width, 3) of type uint8 -> 0 to 255\n",
    "    if not ret:\n",
    "        print(\"Frame not received\")\n",
    "        break\n",
    "\n",
    "    # Convert to grayscale (Aruco works on grayscale)\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) # gray is an array of shape (heigh, width, 1) type uint8\n",
    "\n",
    "    # Detect markers\n",
    "    corners, ids, _ = cv2.aruco.detectMarkers(gray, aruco_dict, parameters=aruco_params) \n",
    "    # corners = list of of length = number of detected markers, shape (1,4,2) 1=default, 4=4corners, 2=(x,y)coor of each corner\n",
    "    # corners[i][0] = x coor of corner j\n",
    "    # ids = numy array of shape (N,1) with N = # of markers, where each element = id#. e.g. [[3], [17], [42]]\n",
    "    # _ = rejected = list of candidate corners that looked like markers but did not match strongly enough\n",
    "\n",
    "    # Draw a square around each marker by connecting its 4 corners with id text (e.g. id:17) next to drawing\n",
    "    if ids is not None:\n",
    "        cv2.aruco.drawDetectedMarkers(frame, corners, ids) \n",
    "\n",
    "    # Show the frame\n",
    "    cv2.imshow(\"Aruco Feed\", frame)\n",
    "    # \"Aruco Feed\" is the window name (string)\n",
    "    # Opens a window on your desktop and blits the image there BUT the window won’t update unless you also call cv2.waitKey()\n",
    "    # regularly in your loop, because that’s when OpenCV processes GUI events.\n",
    "\n",
    "    # Quit with q \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'): \n",
    "        break\n",
    "\n",
    "    # waitKey(1): waits ~1 ms -> processes window events (refresh, close button, etc.) \n",
    "    # -> returns the pressed key if any\n",
    "    # -> Without waitKey, your window will freeze or not show at all.\n",
    "    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ce43ad-0b52-4cc7-9f79-5a03ed2351ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 # Import the OpenCV library\n",
    "import numpy as np # Import Numpy library\n",
    " \n",
    "# Project: ArUco Marker Detector\n",
    "# Date created: 12/18/2021\n",
    "# Python version: 3.8\n",
    "# Reference: https://www.pyimagesearch.com/2020/12/21/detecting-aruco-markers-with-opencv-and-python/\n",
    " \n",
    "desired_aruco_dictionary = \"DICT_ARUCO_ORIGINAL\"\n",
    " \n",
    "# The different ArUco dictionaries built into the OpenCV library. \n",
    "ARUCO_DICT = {\n",
    "  \"DICT_4X4_50\": cv2.aruco.DICT_4X4_50,\n",
    "  \"DICT_4X4_100\": cv2.aruco.DICT_4X4_100,\n",
    "  \"DICT_4X4_250\": cv2.aruco.DICT_4X4_250,\n",
    "  \"DICT_4X4_1000\": cv2.aruco.DICT_4X4_1000,\n",
    "  \"DICT_5X5_50\": cv2.aruco.DICT_5X5_50,\n",
    "  \"DICT_5X5_100\": cv2.aruco.DICT_5X5_100,\n",
    "  \"DICT_5X5_250\": cv2.aruco.DICT_5X5_250,\n",
    "  \"DICT_5X5_1000\": cv2.aruco.DICT_5X5_1000,\n",
    "  \"DICT_6X6_50\": cv2.aruco.DICT_6X6_50,\n",
    "  \"DICT_6X6_100\": cv2.aruco.DICT_6X6_100,\n",
    "  \"DICT_6X6_250\": cv2.aruco.DICT_6X6_250,\n",
    "  \"DICT_6X6_1000\": cv2.aruco.DICT_6X6_1000,\n",
    "  \"DICT_7X7_50\": cv2.aruco.DICT_7X7_50,\n",
    "  \"DICT_7X7_100\": cv2.aruco.DICT_7X7_100,\n",
    "  \"DICT_7X7_250\": cv2.aruco.DICT_7X7_250,\n",
    "  \"DICT_7X7_1000\": cv2.aruco.DICT_7X7_1000,\n",
    "  \"DICT_ARUCO_ORIGINAL\": cv2.aruco.DICT_ARUCO_ORIGINAL\n",
    "}\n",
    "  \n",
    "\n",
    "# Check that we have a valid ArUco marker\n",
    "if ARUCO_DICT.get(desired_aruco_dictionary, None) is None:\n",
    "print(\"[INFO] ArUCo tag of '{}' is not supported\".format(\n",
    "  args[\"type\"]))\n",
    "sys.exit(0)\n",
    " \n",
    "# Load the ArUco dictionary\n",
    "print(\"[INFO] detecting '{}' markers...\".format(\n",
    "desired_aruco_dictionary))\n",
    "this_aruco_dictionary = cv2.aruco.Dictionary_get(ARUCO_DICT[desired_aruco_dictionary])\n",
    "this_aruco_parameters = cv2.aruco.DetectorParameters_create()\n",
    "\n",
    "# Start the video stream\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while(True):\n",
    "\n",
    "# Capture frame-by-frame\n",
    "# This method returns True/False as well\n",
    "# as the video frame.\n",
    "ret, frame = cap.read()  \n",
    " \n",
    "# Detect ArUco markers in the video frame\n",
    "(corners, ids, rejected) = cv2.aruco.detectMarkers(\n",
    "  frame, this_aruco_dictionary, parameters=this_aruco_parameters)\n",
    "   \n",
    "# Check that at least one ArUco marker was detected\n",
    "if len(corners) > 0:\n",
    "  # Flatten the ArUco IDs list\n",
    "  ids = ids.flatten()\n",
    "   \n",
    "  # Loop over the detected ArUco corners\n",
    "  for (marker_corner, marker_id) in zip(corners, ids):\n",
    "   \n",
    "    # Extract the marker corners\n",
    "    corners = marker_corner.reshape((4, 2))\n",
    "    (top_left, top_right, bottom_right, bottom_left) = corners\n",
    "     \n",
    "    # Convert the (x,y) coordinate pairs to integers  \n",
    "    top_right = (int(top_right[0]), int(top_right[1]))\n",
    "    bottom_right = (int(bottom_right[0]), int(bottom_right[1]))\n",
    "    bottom_left = (int(bottom_left[0]), int(bottom_left[1]))\n",
    "    top_left = (int(top_left[0]), int(top_left[1]))\n",
    "     \n",
    "    # Draw the bounding box of the ArUco detection -> cv2.line(image, start_point, end_point, color, thickness)\n",
    "    cv2.line(frame, top_left, top_right, (0, 255, 0), 2)\n",
    "    cv2.line(frame, top_right, bottom_right, (0, 255, 0), 2)\n",
    "    cv2.line(frame, bottom_right, bottom_left, (0, 255, 0), 2)\n",
    "    cv2.line(frame, bottom_left, top_left, (0, 255, 0), 2)\n",
    "     \n",
    "    # Calculate and draw the center of the ArUco marker\n",
    "    center_x = int((top_left[0] + bottom_right[0]) / 2.0)\n",
    "    center_y = int((top_left[1] + bottom_right[1]) / 2.0)\n",
    "    cv2.circle(frame, (center_x, center_y), 4, (0, 0, 255), -1)\n",
    "     \n",
    "    # Draw the ArUco marker ID on the video frame\n",
    "    # The ID is always located at the top_left of the ArUco marker\n",
    "    cv2.putText(frame, str(marker_id), \n",
    "      (top_left[0], top_left[1] - 15),\n",
    "      cv2.FONT_HERSHEY_SIMPLEX,\n",
    "      0.5, (0, 255, 0), 2)\n",
    "\n",
    "# Display the resulting frame\n",
    "cv2.imshow('frame',frame)\n",
    "      \n",
    "# If \"q\" is pressed on the keyboard, \n",
    "# exit this loop\n",
    "if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "  break\n",
    "\n",
    "# Close down the video stream\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223685c7-7c95-4a30-ae81-63381dbba398",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# corners: output from cv2.aruco.detectMarkers\n",
    "# marker0_TL, marker1_BR are the indices of the top-left and bottom-right markers\n",
    "\n",
    "# 1) Image (pixel) coordinates of the 8 corners\n",
    "pts_img_TL = corners[marker0_TL][0].astype(np.float32)  # shape (4,2)\n",
    "pts_img_BR = corners[marker1_BR][0].astype(np.float32)  # shape (4,2)\n",
    "pts_img = np.vstack([pts_img_TL, pts_img_BR])           # shape (8,2)\n",
    "\n",
    "# 2) Real-world coordinates of the same 8 corners\n",
    "#    Order must match the corner order from ArUco: top-left, top-right, bottom-right, bottom-left.\n",
    "#    Top-left marker (you gave: (-6.5,-6.5), (-6.5,0), (0,0), (0,-6.5))\n",
    "pts_world_TL = np.array([\n",
    "    [-6.5, -6.5],   # top-left\n",
    "    [ 0.0, -6.5],   # top-right\n",
    "    [ 0.0,  0.0],   # bottom-right\n",
    "    [-6.5,  0.0],   # bottom-left\n",
    "], dtype=np.float32)\n",
    "\n",
    "#    Bottom-right marker (you gave: (44,28), (51,28), (44,35), (51,35))\n",
    "pts_world_BR = np.array([\n",
    "    [44.0, 28.0],   # top-left\n",
    "    [51.0, 28.0],   # top-right\n",
    "    [51.0, 35.0],   # bottom-right\n",
    "    [44.0, 35.0],   # bottom-left\n",
    "], dtype=np.float32)\n",
    "\n",
    "pts_world = np.vstack([pts_world_TL, pts_world_BR])     # shape (8,2)\n",
    "\n",
    "# 3) Compute homography: image -> world\n",
    "H, inliers = cv2.findHomography(pts_img, pts_world, method=0)  # method=0: direct linear transform\n",
    "\n",
    "# 4) Helper: map a single image point (u,v) to world (X,Y)\n",
    "def img_to_world(pt_uv, H):\n",
    "    uv1 = np.array([pt_uv[0], pt_uv[1], 1.0], dtype=np.float32)\n",
    "    XY1 = H @ uv1\n",
    "    XY1 /= XY1[2]\n",
    "    return float(XY1[0]), float(XY1[1])\n",
    "\n",
    "# Example usage:\n",
    "# robot_center_img = (u, v) from your robot marker\n",
    "# X_r, Y_r = img_to_world(robot_center_img, H)\n",
    "\n",
    "# for obstacles use \n",
    "#cnt = contour.reshape(-1, 1, 2).astype(np.float32)   # (N,1,2)\n",
    "#cnt_world = cv2.perspectiveTransform(cnt, H)         # (N,1,2) in real-world coord#s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1480b10c-a11f-469a-bba5-4783ec05463a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2, numpy as np\n",
    "\n",
    "print(\"cv2 module:\", cv2)\n",
    "print(\"cv2 file:\", getattr(cv2, \"__file__\", \"no __file__\"))\n",
    "print(\"cv2 version:\", cv2.__version__)\n",
    "print(\"type(getPerspectiveTransform):\", type(cv2.getPerspectiveTransform))\n",
    "\n",
    "srcPoints = np.array([[100, 100],\n",
    "                      [150, 100],\n",
    "                      [150, 150],\n",
    "                      [100, 150]], dtype=np.float32)\n",
    "dstPoints = np.array([[200, 200],\n",
    "                      [250, 200],\n",
    "                      [250, 250],\n",
    "                      [200, 250]], dtype=np.float32)\n",
    "\n",
    "print(\"src type/shape/dtype:\", type(srcPoints), srcPoints.shape, srcPoints.dtype)\n",
    "print(\"dst type/shape/dtype:\", type(dstPoints), dstPoints.shape, dstPoints.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af5b380c-3c84-4d64-878a-fc015148b446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src type/shape/dtype: <class 'numpy.ndarray'> (4, 2) float32\n",
      "dst type/shape/dtype: <class 'numpy.ndarray'> (4, 2) float32\n",
      "Homography Matrix:\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Define source and destination points\n",
    "srcPoints = np.array([[100, 100], [150, 100], [150, 150], [100, 150]], dtype=np.float32)\n",
    "dstPoints = np.array([[200, 200], [250, 200], [250, 250], [200, 250]], dtype=np.float32)\n",
    "\n",
    "print(\"src type/shape/dtype:\", type(srcPoints), srcPoints.shape, srcPoints.dtype)\n",
    "print(\"dst type/shape/dtype:\", type(dstPoints), dstPoints.shape, dstPoints.dtype)\n",
    "# Compute homography matrix\n",
    "H, mask = cv2.findHomography(srcPoints, dstPoints, cv2.RANSAC, 5.0)\n",
    "\n",
    "# Print the resulting homography matrix\n",
    "print(\"Homography Matrix:\")\n",
    "# print(H)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
